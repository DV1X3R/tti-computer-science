{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _LogisticRegression:\n",
    "    \n",
    "    def __init__(self, alpha=0.0001, epsilon=0.1, max_iter=300):\n",
    "        self.alpha = alpha\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.iter = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = np.array(X)\n",
    "        y = y.reshape(-1, 1)\n",
    "        self.intercept_ = np.random.sample()\n",
    "        self.coef_ = np.random.sample((len(X.T), 1))\n",
    "        self.iter = 0\n",
    "\n",
    "        while True:\n",
    "            self.iter += 1\n",
    "            if self.iter > self.max_iter:\n",
    "                break\n",
    "\n",
    "            e = np.ones(len(X))\n",
    "            z = self._z(X)\n",
    "            y_cap = self._sigmoid(z)\n",
    "            \n",
    "            delta_b = -self.alpha * -e.dot(y - y_cap)\n",
    "            delta_w = -self.alpha * -X.T.dot(y - y_cap)\n",
    "            self.intercept_ += delta_b[0]\n",
    "            self.coef_ += delta_w\n",
    "            if (delta_b[0] ** 2) + (delta_w ** 2).sum() < self.epsilon:\n",
    "                break\n",
    "                \n",
    "        return self\n",
    "        \n",
    "    # weighted input function\n",
    "    def _z(self, X):\n",
    "        return X.dot(self.coef_) + self.intercept_\n",
    "        \n",
    "    # logistic function\n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    # quantizer\n",
    "    def _q(self, a):\n",
    "        return np.where(a < 0.5, 0, 1)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        z = self._z(X)\n",
    "        y_cap = self._sigmoid(z)\n",
    "        q = self._q(y_cap)    \n",
    "        return q.reshape(1, -1)[0]\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        return accuracy_score(y, self.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'sex', 'cp', 'trestbps','chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat', delimiter=' ', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['sex', 'fbs', 'exang'])\n",
    "target_attribute = ['num']\n",
    "all_fields = list(df.drop(target_attribute, axis=1))\n",
    "df[target_attribute] = np.where(df[target_attribute] == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[all_fields], df[target_attribute], test_size=0.2)\n",
    "y_train = np.array(y_train).reshape(1,-1)[0]\n",
    "y_test = np.array(y_test).reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = _LogisticRegression(alpha=0.00003, epsilon=0.001).fit(X_train, y_train)\n",
    "#model = LogisticRegression(solver='liblinear').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total iterations 301\n",
      "train set accuracy 0.6157407407407407\n",
      "test set accuracy 0.6481481481481481\n"
     ]
    }
   ],
   "source": [
    "print('total iterations', model.iter)\n",
    "print('train set accuracy', model.score(X_train, y_train))\n",
    "print('test set accuracy', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
