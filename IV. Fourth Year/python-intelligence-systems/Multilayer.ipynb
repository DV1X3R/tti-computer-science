{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayer Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn.utils as skutils\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multilayer:\n",
    "\n",
    "    def __init__(self, l_in, l_hidden, seed=np.random.randint(1000), alpha=0.01, l2_lambda=0):\n",
    "        self.alpha = alpha\n",
    "        self.l2_lambda = l2_lambda\n",
    "        self.m = [l_in] + list(l_hidden) + [1]  # neurons per layer\n",
    "        self.L = len(self.m)  # number of layers (depth = -1)\n",
    "\n",
    "        self.fa = {}  # activation functions per layer\n",
    "        self.fd = {}  # activation function derivatives per layer\n",
    "\n",
    "        l = self.L - 1  # last layer activation\n",
    "        self.fa[l] = Multilayer.a_sigmoid\n",
    "        self.fd[l] = Multilayer.d_sigmoid\n",
    "\n",
    "        # hidden layer activations\n",
    "        for l in range(1, self.L - 1):\n",
    "            self.fa[l] = Multilayer.a_relu\n",
    "            self.fd[l] = Multilayer.d_relu\n",
    "\n",
    "        self.A = {}  # activation values per layer per neuron\n",
    "        self.Z = {}  # weighted inputs per layer per neuron\n",
    "        self.W = {}  # weights per layer per neuron (columns)\n",
    "        self.B = {}  # biases per layer per neuron\n",
    "        self.C = {}  # cost per epoch\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        for l in range(1, self.L):\n",
    "            self.W[l] = np.random.normal(loc=0, scale=0.01, size=(self.m[l-1], self.m[l]))\n",
    "            self.B[l] = np.random.normal(loc=0, scale=0.01, size=self.m[l])\n",
    "\n",
    "    def fit(self, X, y, max_epoch=1000, batch_size=None, gradient_check=False):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y).reshape(-1, 1)\n",
    "        current_epoch = 0\n",
    "\n",
    "        while current_epoch < max_epoch:\n",
    "            current_epoch += 1\n",
    "            for Xb, yb in Multilayer.create_batches(X, y, batch_size):\n",
    "                self.A[0] = Xb\n",
    "                self.y = yb\n",
    "                self.Z, self.A = self.forward_pass()\n",
    "                self.W, self.B = self.backward_pass()\n",
    "                self.C[current_epoch] = self.cost(X, y)\n",
    "                if gradient_check:\n",
    "                    self.gradient_check()\n",
    "                \n",
    "        return self\n",
    "\n",
    "    def forward_pass(self, W=None, B=None):\n",
    "        W = self.W if W is None else W\n",
    "        B = self.B if B is None else B\n",
    "        Z = self.Z.copy()\n",
    "        A = self.A.copy()\n",
    "        \n",
    "        # Step 1\n",
    "        for l in range(1, self.L):\n",
    "            Z[l] = A[l-1].dot(W[l]) + B[l]\n",
    "            A[l] = self.fa[l](Z[l])\n",
    "        \n",
    "        return Z, A\n",
    "\n",
    "    def backward_pass(self):\n",
    "        delta_A, delta_Z, delta_W, delta_B = {}, {}, {}, {}\n",
    "\n",
    "        for l in range(self.L - 1, 0, -1):\n",
    "            # Step 2. A\n",
    "            if l == self.L - 1:\n",
    "                delta_A[l] = ((1 - self.y) / (1 - self.A[l])) - (self.y / self.A[l])\n",
    "                delta_Z[l] = self.A[l] - self.y  # delta_A[l] * self.fd[l](self.Z[l])\n",
    "            else:\n",
    "                delta_A[l] = delta_Z[l+1].dot(self.W[l+1].T)\n",
    "                delta_Z[l] = delta_A[l] * self.fd[l](self.Z[l])\n",
    "\n",
    "            # Step 2. B\n",
    "            delta_W[l] = self.A[l-1].T.dot(delta_Z[l]) + ((self.l2_lambda / 2) * (self.W[l] ** 2))\n",
    "            delta_B[l] = delta_Z[l].sum() / len(delta_Z[l])\n",
    "\n",
    "        W = self.W.copy()\n",
    "        B = self.B.copy()\n",
    "        \n",
    "        # Step 3.\n",
    "        for l in range(1, self.L):\n",
    "            W[l] -= self.alpha * delta_W[l]\n",
    "            B[l] -= self.alpha * delta_B[l]\n",
    "        \n",
    "        return W, B\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        self.A[0] = np.array(X)\n",
    "        self.Z, self.A = self.forward_pass()\n",
    "        self.y = Multilayer.q_sigmoid(self.A[self.L - 1], threshold)\n",
    "        return self\n",
    "\n",
    "    def score(self, X, y, threshold=0.5):\n",
    "        return accuracy_score(y, self.predict(X, threshold).y)\n",
    "    \n",
    "    def cost(self, X, y):\n",
    "        y_cap = self.predict(X).A[self.L - 1]\n",
    "        return -((y * np.log(y_cap)) + (1 - y) * np.log(1 - y_cap)).sum()\n",
    "    \n",
    "    def gradient_check(self):\n",
    "        {}\n",
    "    \n",
    "    def create_batches(X, y, batch_size):\n",
    "        Xb, yb = skutils.shuffle(X, y)\n",
    "        batches = (int)(len(X) / (batch_size or len(X)))\n",
    "        Xb = np.array_split(Xb, batches)\n",
    "        yb = np.array_split(yb, batches)\n",
    "        return zip(Xb, yb)\n",
    "    \n",
    "    def q_sigmoid(a, threshold=0.5):  # quantizer\n",
    "        return np.where(a < threshold, 0, 1)\n",
    "\n",
    "    def a_sigmoid(z):  # logistic function\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def d_sigmoid(z):  # sigmoid derivative (2.A validation)\n",
    "        a = Multilayer.a_sigmoid(z)\n",
    "        return a * (1 - a)\n",
    "\n",
    "    def a_relu(z):  # rectified linear unit\n",
    "        return np.where(z > 0, z, 0)\n",
    "\n",
    "    def d_relu(z):  # relu derivative\n",
    "        return np.where(z > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XOR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.randn(500, 2)\n",
    "y = np.where(np.logical_xor(X[:, 0] > 0, X[:, 1] > 0), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer(l_in=2, l_hidden=[3], seed=1, alpha=0.01).fit(X, y, max_epoch=40, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=model.predict(X).y[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(model.C.keys()), y=list(model.C.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circles Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_circles = datasets.make_circles(n_samples=1000, factor=.5, noise=.05)\n",
    "X, y = noisy_circles[0], noisy_circles[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer(l_in=2, l_hidden=[5], seed=1, alpha=0.05).fit(X, y, max_epoch=10, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=model.predict(X).y[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(model.C.keys()), y=list(model.C.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moons Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "noisy_moons = datasets.make_moons(n_samples=1000, noise=.05)\n",
    "X, y = noisy_moons[0], noisy_moons[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer(l_in=2, l_hidden=[6], seed=0, alpha=0.05).fit(X, y, max_epoch=40, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=X[:, 0], y=X[:, 1], hue=model.predict(X).y[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(model.C.keys()), y=list(model.C.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart Disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['age', 'sex', 'cp', 'trestbps','chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num']\n",
    "df = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/statlog/heart/heart.dat', delimiter=' ', names=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_attributes = [0,3,4,7,9,11]\n",
    "ordered_attributes = [10]\n",
    "binary_attributes = [1,5,8]\n",
    "nominal_attributes = [6,2,12]\n",
    "target_attribute = 'num'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_attribute] = np.where(df[target_attribute] == 1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,real_attributes] = StandardScaler().fit_transform(df.iloc[:,real_attributes])\n",
    "df.iloc[:,ordered_attributes] = Normalizer().fit_transform(df.iloc[:,ordered_attributes])\n",
    "df = pd.get_dummies(df, columns=df.columns[nominal_attributes], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fields = list(df.drop(target_attribute, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[all_fields], np.array(df[target_attribute]), test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Multilayer(l_in=len(X_train.T), l_hidden=[3], seed=0, alpha=0.01, l2_lambda=0.05).fit(X_train, y_train, max_epoch=200, batch_size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(x=list(model.C.keys()), y=list(model.C.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train set', model.score(X_train, y_train))\n",
    "print('test set', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
